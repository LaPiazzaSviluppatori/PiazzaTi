# -*- coding: utf-8 -*-
"""Xai.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bAK1CinFt9WEcX4hINcjk_5MnjVOG8dK
"""

"""
XAI Builder - Explainable AI Module for CV-JD Matching
======================================================

Genera spiegazioni deterministiche e interpretabili per i risultati del matching.
Non usa LLM: tutte le spiegazioni derivano direttamente dalle feature e dai pesi del modello.

INPUT:  rerank_results/rerank_output.json (output del reranker)
OUTPUT: xai_output/xai_YYYY-MM-DD_HH-MM-SS.json

Questo modulo prende l'output del reranker (feature_values, feature_contributions, score_breakdown)
e produce:
- top_reasons: 3-5 motivi positivi che spiegano il match
- main_risks: 1-3 rischi/gap identificati
- evidence: dati concreti a supporto (skills matched, gaps, etc.)

Uso da riga di comando:
    python xai_builder.py

Uso come modulo:
    from xai_builder import build_xai_company, build_xai_batch, run_xai_pipeline

    # Per processare l'intero output del reranker
    output_path = run_xai_pipeline()

    # Per un singolo candidato
    xai = build_xai_company(candidate_data, details)

    # Per batch (top 20 candidati di una JD)
    xai_list = build_xai_batch(candidates_list, jd_info)
"""

import json
from pathlib import Path
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, field
from datetime import datetime


# ============================================================================
# CONFIGURAZIONE
# ============================================================================

@dataclass
class XAIConfig:
    """
    Configurazione per il modulo XAI.
    """
    # Input: output del reranker
    RERANKER_OUTPUT_PATH: str = "rerank_results/rerank_output.json"

    # Output: cartella dove salvare i risultati XAI
    OUTPUT_DIR: str = "xai_output"

    # Pesi del modello (per reference nei metadata) - v1.2
    MODEL_WEIGHTS: Dict[str, float] = field(default_factory=lambda: {
        'cosine_similarity_normalized': 0.45,
        'skill_overlap_core_norm': 0.30,
        'skill_coverage_total': 0.15,
        'skill_overlap_nice_norm': 0.075,
        'experience_meets_requirement': 0.30,
        'seniority_match': 0.075,
        'role_similarity_jaccard': 0.10,
        'role_coherent': 0.10,
        'must_have_missing': -0.075,
        'experience_penalty_soft': -0.15,
        'seniority_mismatch_strong': -0.225,
        'seniority_underskilled': -0.075,
    })


DEFAULT_CONFIG = XAIConfig()


# ============================================================================
# CONFIGURAZIONE SOGLIE
# ============================================================================

@dataclass
class XAIThresholds:
    """
    Soglie per la generazione delle spiegazioni.
    Calibrate per i pesi v1.2 del modello.

    Nota: queste soglie determinano QUANDO un motivo/rischio viene generato,
    non il valore dello score (che è calcolato dal reranker).
    """
    # Soglie per reasons positive
    COSINE_STRONG: float = 0.65      # Similarità semantica forte
    COSINE_MODERATE: float = 0.45    # Similarità semantica moderata
    SKILL_CORE_STRONG: float = 0.6   # Oltre 60% delle skill core
    SKILL_CORE_PARTIAL: float = 0.2  # Almeno 20% delle skill core
    SKILL_NICE_THRESHOLD: float = 0.25  # Nice-to-have skills
    ROLE_SIMILARITY_MIN: float = 0.2    # Soglia minima per role coherent

    # Soglie per risks
    MISSING_SKILLS_HIGH: int = 2       # 2+ skill mancanti = severity high
    EXPERIENCE_GAP_HIGH: float = 1.5   # Gap esperienza critico (anni)


DEFAULT_THRESHOLDS = XAIThresholds()


# ============================================================================
# TEMPLATE TESTUALI
# ============================================================================
# I testi sono in italiano perché il sistema è per il mercato italiano.
# Possono essere facilmente estratti in un file di localizzazione se necessario.

REASON_TEMPLATES = {
    # Semantic match
    "semantic_match_strong": "Il profilo complessivo è fortemente allineato con la posizione",
    "semantic_match_moderate": "Il profilo mostra buon allineamento con la posizione",

    # Skills
    "core_skills_strong": "Possiede la maggior parte delle competenze core richieste",
    "core_skills_partial": "Possiede alcune delle competenze core richieste",
    "nice_skills_present": "Ha competenze aggiuntive desiderate (nice-to-have)",

    # Experience
    "experience_sufficient": "L'esperienza soddisfa i requisiti minimi",
    "experience_exceeds": "L'esperienza supera i requisiti richiesti",

    # Seniority
    "seniority_aligned": "Il livello di seniority corrisponde alla posizione",
    "seniority_higher": "Ha seniority superiore a quella richiesta",

    # Role
    "role_aligned": "Il ruolo attuale è coerente con la posizione",
}

RISK_TEMPLATES = {
    # Skills
    "missing_core_skills_high": "Mancano diverse competenze core richieste",
    "missing_core_skills_medium": "Mancano alcune competenze core richieste",

    # Experience
    "experience_below_critical": "Esperienza significativamente sotto il requisito minimo",
    "experience_below_minor": "Esperienza leggermente sotto il requisito minimo",

    # Seniority
    "seniority_gap_critical": "Differenza di seniority significativa (≥2 livelli)",
    "underskilled": "Seniority inferiore a quella richiesta",
    "overskilled": "Seniority superiore - potrebbe essere overqualified",
}


# ============================================================================
# FUNZIONI CORE
# ============================================================================

def build_top_reasons(
    feature_values: Dict[str, float],
    feature_contributions: Dict[str, float],
    details: Dict[str, Any],
    experience_details: Optional[Dict[str, Any]] = None,
    seniority_details: Optional[Dict[str, Any]] = None,
    skills_details: Optional[Dict[str, Any]] = None,
    thresholds: XAIThresholds = DEFAULT_THRESHOLDS
) -> List[Dict[str, Any]]:
    """
    Genera i top motivi positivi per il match.

    La logica è deterministica: per ogni feature, se il valore supera
    una certa soglia, viene generato un motivo corrispondente.
    I motivi sono poi ordinati per contributo allo score e limitati a 5.

    Args:
        feature_values: Valori delle feature (es. cosine_similarity_normalized: 0.7)
        feature_contributions: Contributi allo score (w_i * x_i)
        details: Dettagli aggiuntivi (legacy)
        experience_details: Dettagli esperienza dal reranker
        seniority_details: Dettagli seniority dal reranker
        skills_details: Dettagli skills dal reranker
        thresholds: Soglie per la generazione dei motivi

    Returns:
        Lista di motivi, ordinati per contributo decrescente, max 5 elementi
    """
    reasons = []

    # 1. SEMANTIC SIMILARITY (solo testo qualitativo, no percentuale)
    cosine_val = feature_values.get('cosine_similarity_normalized', 0)
    cosine_contrib = feature_contributions.get('cosine_similarity_normalized', 0)

    if cosine_val >= thresholds.COSINE_STRONG:
        reasons.append({
            "reason_id": "semantic_match_strong",
            "category": "profile_fit",
            "text": REASON_TEMPLATES["semantic_match_strong"],
            "contribution": round(cosine_contrib, 4),
            "evidence": "Competenze ed esperienze in linea con il ruolo"
        })
    elif cosine_val >= thresholds.COSINE_MODERATE:
        reasons.append({
            "reason_id": "semantic_match_moderate",
            "category": "profile_fit",
            "text": REASON_TEMPLATES["semantic_match_moderate"],
            "contribution": round(cosine_contrib, 4),
            "evidence": "Background professionale compatibile"
        })

    # 2. CORE SKILLS OVERLAP (usa skills_details)
    skill_core_val = feature_values.get('skill_overlap_core_norm', 0)
    skill_core_contrib = feature_contributions.get('skill_overlap_core_norm', 0)

    if skills_details:
        matched = skills_details.get('cv_skills_matched', 0)
        plural = "i" if matched != 1 else "e"
        skill_evidence = f"{matched} skill core present{plural}"
    else:
        skill_evidence = "N/A"

    if skill_core_val >= thresholds.SKILL_CORE_STRONG:
        reasons.append({
            "reason_id": "core_skills_strong",
            "category": "skills",
            "text": REASON_TEMPLATES["core_skills_strong"],
            "contribution": round(skill_core_contrib, 4),
            "evidence": skill_evidence
        })
    elif skill_core_val >= thresholds.SKILL_CORE_PARTIAL:
        reasons.append({
            "reason_id": "core_skills_partial",
            "category": "skills",
            "text": REASON_TEMPLATES["core_skills_partial"],
            "contribution": round(skill_core_contrib, 4),
            "evidence": skill_evidence
        })

    # 3. NICE-TO-HAVE SKILLS (usa skills_details)
    skill_nice_val = feature_values.get('skill_overlap_nice_norm', 0)
    skill_nice_contrib = feature_contributions.get('skill_overlap_nice_norm', 0)

    if skills_details:
        nice_matched = skills_details.get('nice_to_have_matched', 0)
        nice_evidence = f"{nice_matched} skill nice-to-have presenti"
    else:
        nice_matched = 0
        nice_evidence = "N/A"

    if skill_nice_val >= thresholds.SKILL_NICE_THRESHOLD and nice_matched > 0:
        reasons.append({
            "reason_id": "nice_skills_present",
            "category": "skills",
            "text": REASON_TEMPLATES["nice_skills_present"],
            "contribution": round(skill_nice_contrib, 4),
            "evidence": nice_evidence
        })

    # 4. EXPERIENCE (usa experience_details) - numeri interi
    exp_meets = feature_values.get('experience_meets_requirement', 0)
    exp_contrib = feature_contributions.get('experience_meets_requirement', 0)

    if experience_details:
        years_cv = experience_details.get('cv_years', 0)
        years_jd = experience_details.get('required_years', 0)
    else:
        years_cv = details.get('years_experience_cv', 0)
        years_jd = details.get('years_required_jd', 0)

    # Converti in interi
    years_cv_int = int(round(years_cv))
    years_jd_int = int(round(years_jd))

    if exp_meets == 1.0:
        exp_evidence = f"{years_cv_int} anni (richiesti: {years_jd_int})"
        # Verifica se supera di molto il requisito
        if years_jd > 0 and years_cv >= years_jd * 1.5:
            reasons.append({
                "reason_id": "experience_exceeds",
                "category": "experience",
                "text": REASON_TEMPLATES["experience_exceeds"],
                "contribution": round(exp_contrib, 4),
                "evidence": exp_evidence
            })
        else:
            reasons.append({
                "reason_id": "experience_sufficient",
                "category": "experience",
                "text": REASON_TEMPLATES["experience_sufficient"],
                "contribution": round(exp_contrib, 4),
                "evidence": exp_evidence
            })

    # 5. SENIORITY MATCH (usa seniority_details)
    seniority_match = feature_values.get('seniority_match', 0)
    seniority_contrib = feature_contributions.get('seniority_match', 0)

    if seniority_details:
        seniority_cv = seniority_details.get('cv_seniority', '')
        seniority_jd = seniority_details.get('required_seniority', '')
        seniority_gap = seniority_details.get('gap', 0)
    else:
        seniority_cv = details.get('seniority_cv', '')
        seniority_jd = details.get('seniority_jd', '')
        seniority_gap = 0

    if seniority_match == 1.0 and seniority_cv and seniority_jd:
        reasons.append({
            "reason_id": "seniority_aligned",
            "category": "seniority",
            "text": REASON_TEMPLATES["seniority_aligned"],
            "contribution": round(seniority_contrib, 4),
            "evidence": f"Seniority: {seniority_cv} (richiesta: {seniority_jd})"
        })
    elif seniority_gap > 0 and seniority_cv and seniority_jd:
        # CV ha seniority più alta della JD
        reasons.append({
            "reason_id": "seniority_higher",
            "category": "seniority",
            "text": REASON_TEMPLATES["seniority_higher"],
            "contribution": round(seniority_contrib, 4),
            "evidence": f"Seniority: {seniority_cv} > {seniority_jd} richiesta"
        })

    # 6. ROLE COHERENT
    role_coherent = feature_values.get('role_coherent', 0)
    role_contrib = feature_contributions.get('role_coherent', 0)
    cv_role = details.get('cv_current_role', '')

    if role_coherent == 1.0 and cv_role:
        reasons.append({
            "reason_id": "role_aligned",
            "category": "role",
            "text": REASON_TEMPLATES["role_aligned"],
            "contribution": round(role_contrib, 4),
            "evidence": f"Ruolo attuale: {cv_role}"
        })

    # Ordina per contributo (decrescente) e ritorna top 5
    reasons.sort(key=lambda x: x['contribution'], reverse=True)
    return reasons[:5]


def build_main_risks(
    feature_values: Dict[str, float],
    feature_contributions: Dict[str, float],
    details: Dict[str, Any],
    experience_details: Optional[Dict[str, Any]] = None,
    seniority_details: Optional[Dict[str, Any]] = None,
    skills_details: Optional[Dict[str, Any]] = None,
    thresholds: XAIThresholds = DEFAULT_THRESHOLDS
) -> List[Dict[str, Any]]:
    """
    Genera i principali rischi/gap del match.

    I rischi sono identificati quando le feature penalty hanno valori significativi
    o quando i flag indicano problemi specifici.

    Args:
        feature_values: Valori delle feature
        feature_contributions: Contributi allo score (negativi per le penalty)
        details: Dettagli aggiuntivi (legacy)
        experience_details: Dettagli esperienza dal reranker
        seniority_details: Dettagli seniority dal reranker
        skills_details: Dettagli skills dal reranker
        thresholds: Soglie per la classificazione di severità

    Returns:
        Lista di rischi, ordinati per severità e impatto, max 3 elementi
    """
    risks = []

    # 1. MUST-HAVE SKILLS MANCANTI (usa skills_details)
    must_have_missing = feature_values.get('must_have_missing', 0)
    must_have_contrib = feature_contributions.get('must_have_missing', 0)

    if must_have_missing > 0:
        if skills_details:
            missing_count = skills_details.get('must_have_missing', int(must_have_missing))
        else:
            missing_count = int(must_have_missing)

        skill_evidence = f"{missing_count} skill core non chiaramente esplicite nel CV"

        severity = "high" if missing_count >= thresholds.MISSING_SKILLS_HIGH else "medium"
        template_key = f"missing_core_skills_{severity}"

        risks.append({
            "risk_id": "missing_core_skills",
            "category": "skills",
            "severity": severity,
            "text": f"{RISK_TEMPLATES[template_key]} ({missing_count})",
            "contribution": round(must_have_contrib, 4),
            "evidence": skill_evidence,
            "missing_count": missing_count
        })

    # 2. STRONG SENIORITY MISMATCH (usa seniority_details)
    seniority_mismatch = feature_values.get('seniority_mismatch_strong', 0)
    seniority_mismatch_contrib = feature_contributions.get('seniority_mismatch_strong', 0)

    if seniority_details:
        seniority_cv = seniority_details.get('cv_seniority', '')
        seniority_jd = seniority_details.get('required_seniority', '')
    else:
        seniority_cv = details.get('seniority_cv', '')
        seniority_jd = details.get('seniority_jd', '')

    if seniority_mismatch == 1.0:
        if seniority_cv and seniority_jd:
            seniority_evidence = f"Candidato: {seniority_cv}, richiesta: {seniority_jd}"
        else:
            seniority_evidence = "Gap di 2+ livelli"

        risks.append({
            "risk_id": "seniority_gap_critical",
            "category": "seniority",
            "severity": "high",
            "text": RISK_TEMPLATES["seniority_gap_critical"],
            "contribution": round(seniority_mismatch_contrib, 4),
            "evidence": seniority_evidence
        })

    # 3. UNDERSKILLED (seniority CV < JD) - usa seniority_details
    underskilled = feature_values.get('seniority_underskilled', 0)
    underskilled_contrib = feature_contributions.get('seniority_underskilled', 0)

    # Evita duplicati: se già abbiamo seniority_gap_critical, non aggiungere underskilled
    has_seniority_critical = any(r['risk_id'] == 'seniority_gap_critical' for r in risks)

    if underskilled == 1.0 and not has_seniority_critical:
        if seniority_cv and seniority_jd:
            underskilled_evidence = f"Candidato: {seniority_cv}, richiesta: {seniority_jd}"
        else:
            underskilled_evidence = "Seniority insufficiente"

        risks.append({
            "risk_id": "underskilled",
            "category": "seniority",
            "severity": "medium",
            "text": RISK_TEMPLATES["underskilled"],
            "contribution": round(underskilled_contrib, 4),
            "evidence": underskilled_evidence
        })

    # 4. ESPERIENZA INSUFFICIENTE (usa experience_details) - numeri interi
    exp_meets = feature_values.get('experience_meets_requirement', 1)
    exp_penalty = feature_values.get('experience_penalty_soft', 0)
    exp_penalty_contrib = feature_contributions.get('experience_penalty_soft', 0)

    if experience_details:
        years_cv = experience_details.get('cv_years', 0)
        years_jd = experience_details.get('required_years', 0)
    else:
        years_cv = details.get('years_experience_cv', 0)
        years_jd = details.get('years_required_jd', 0)

    if exp_meets == 0 and years_jd > 0:
        gap = years_jd - years_cv
        gap_int = int(round(gap))
        years_cv_int = int(round(years_cv))
        years_jd_int = int(round(years_jd))

        severity = "high" if gap >= thresholds.EXPERIENCE_GAP_HIGH else "medium"
        template_key = f"experience_below_{'critical' if severity == 'high' else 'minor'}"

        risks.append({
            "risk_id": "experience_below_requirement",
            "category": "experience",
            "severity": severity,
            "text": f"{RISK_TEMPLATES[template_key]} ({gap_int} anni di gap)",
            "contribution": round(exp_penalty_contrib, 4),
            "evidence": f"Candidato: {years_cv_int} anni, richiesti: {years_jd_int} anni"
        })

    # Ordina per severità (high prima) e poi per impatto negativo
    severity_order = {"high": 0, "medium": 1, "low": 2}
    risks.sort(key=lambda x: (severity_order.get(x['severity'], 2), x['contribution']))

    return risks[:3]


def build_evidence_summary(
    feature_values: Dict[str, float],
    details: Dict[str, Any],
    experience_details: Optional[Dict[str, Any]] = None,
    seniority_details: Optional[Dict[str, Any]] = None,
    skills_details: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """
    Costruisce un riepilogo delle evidenze concrete.

    Questa sezione fornisce i dati grezzi che supportano reasons e risks,
    utili per il frontend o per debug.

    Args:
        feature_values: Valori delle feature
        details: Dettagli dal matching (legacy format)
        experience_details: Dettagli esperienza dal reranker
        seniority_details: Dettagli seniority dal reranker
        skills_details: Dettagli skills dal reranker

    Returns:
        Dict con tutte le evidenze rilevanti
    """
    # Skills evidence - usa skills_details se disponibile
    if skills_details:
        skills_matched = skills_details.get('cv_skills_matched', 0)
        skills_required = skills_details.get('jd_skills_required', 0)
        skills_missing = skills_details.get('must_have_missing', 0)
        nice_matched = skills_details.get('nice_to_have_matched', 0)
        nice_total = skills_details.get('nice_to_have_total', 0)
    else:
        skills_matched = len(details.get('skills_matched', []))
        skills_required = len(details.get('jd_requirements', []))
        skills_missing = skills_required - skills_matched
        nice_matched = len(details.get('skills_nice_matched', []))
        nice_total = len(details.get('jd_nice_to_have', []))

    # Experience evidence - usa experience_details se disponibile
    if experience_details:
        years_cv = experience_details.get('cv_years', 0)
        years_jd = experience_details.get('required_years', 0)
        experience_gap = experience_details.get('gap', years_cv - years_jd)
    else:
        years_cv = details.get('years_experience_cv', 0)
        years_jd = details.get('years_required_jd', 0)
        experience_gap = years_cv - years_jd

    # Seniority evidence - usa seniority_details se disponibile
    if seniority_details:
        seniority_cv = seniority_details.get('cv_seniority', '')
        seniority_jd = seniority_details.get('required_seniority', '')
        seniority_gap = seniority_details.get('gap', 0)
    else:
        seniority_cv = details.get('seniority_cv', '')
        seniority_jd = details.get('seniority_jd', '')
        # Calcola seniority gap come numero
        seniority_levels = {'junior': 1, 'mid': 2, 'senior': 3}
        cv_level = seniority_levels.get(str(seniority_cv).lower(), 0)
        jd_level = seniority_levels.get(str(seniority_jd).lower(), 0)
        seniority_gap = cv_level - jd_level

    return {
        "skills_core_matched": skills_matched,
        "skills_core_required": skills_required,
        "skills_core_missing": skills_missing,
        "skills_nice_matched": nice_matched,
        "skills_nice_total": nice_total,
        "cv_current_role": details.get('cv_current_role', ''),
        "experience_cv_years": int(round(years_cv)),
        "experience_jd_required": int(round(years_jd)),
        "experience_gap": int(round(experience_gap)),
        "seniority_cv": seniority_cv,
        "seniority_jd": seniority_jd,
        "seniority_gap": seniority_gap,
        "cv_completeness": details.get('cv_completeness_score', 0)
    }


# ============================================================================
# FUNZIONI PUBBLICHE (API del modulo)
# ============================================================================

def build_xai_company(
    candidate_data: Dict[str, Any],
    details: Optional[Dict[str, Any]] = None,
    jd_info: Optional[Dict[str, Any]] = None,
    thresholds: XAIThresholds = DEFAULT_THRESHOLDS
) -> Dict[str, Any]:
    """
    Costruisce l'output XAI completo per un singolo candidato (Company View).

    Questa è la funzione principale da chiamare per ottenere le spiegazioni.
    Prende i dati già calcolati dal reranker e aggiunge la parte interpretativa.

    Args:
        candidate_data: Dati del candidato dal reranker, deve contenere:
            - user_id: ID del candidato
            - score: Score finale
            - score_breakdown: {linear_score_raw, linear_score_normalized, dei_boost, final_score}
            - feature_values: Dict delle feature
            - feature_contributions: Dict dei contributi (w_i * x_i)
            - flags: Dict dei flag booleani
            - dei_tags: Dict dei tag DEI
            - experience_details: {cv_years, required_years, gap, meets_requirement}
            - seniority_details: {cv_seniority, required_seniority, gap, match}
            - skills_details: {cv_skills_matched, jd_skills_required, must_have_missing, ...}
        details: Dettagli aggiuntivi legacy (opzionale)
        jd_info: Info sulla JD {jd_id, title}
        thresholds: Soglie per la generazione (default: DEFAULT_THRESHOLDS)

    Returns:
        Dict con struttura XAI completa
    """
    # Estrai i componenti necessari
    feature_values = candidate_data.get('feature_values', {})
    feature_contributions = candidate_data.get('feature_contributions', {})
    score_breakdown = candidate_data.get('score_breakdown', {})

    # Estrai i nuovi details dal reranker
    experience_details = candidate_data.get('experience_details', None)
    seniority_details = candidate_data.get('seniority_details', None)
    skills_details = candidate_data.get('skills_details', None)

    # Se details non forniti, prova a estrarli da candidate_data (legacy)
    if details is None:
        details = candidate_data.get('details', {})

    # Costruisci le spiegazioni
    top_reasons = build_top_reasons(
        feature_values, feature_contributions, details,
        experience_details, seniority_details, skills_details, thresholds
    )
    main_risks = build_main_risks(
        feature_values, feature_contributions, details,
        experience_details, seniority_details, skills_details, thresholds
    )
    evidence = build_evidence_summary(
        feature_values, details,
        experience_details, seniority_details, skills_details
    )

    # Determina quality label
    final_score = candidate_data.get('score', 0)
    if final_score >= 0.5:
        quality_label = "EXCELLENT"
    elif final_score >= 0.3:
        quality_label = "GOOD"
    else:
        quality_label = "WEAK"

    # Costruisci output
    xai_output = {
        "xai_version": "1.0",
        "generated_at": datetime.now().isoformat(),
        "view_type": "company",

        "match_summary": {
            "user_id": candidate_data.get('user_id', ''),
            "jd_id": jd_info.get('jd_id', '') if jd_info else '',
            "jd_title": jd_info.get('title', '') if jd_info else '',
            "final_score": round(final_score, 4),
            "quality_label": quality_label,
            "rank": candidate_data.get('rank', 0)
        },

        "score_breakdown": {
            "linear_score_raw": score_breakdown.get('linear_score_raw', 0),
            "linear_score_normalized": score_breakdown.get('linear_score_normalized', 0),
            "dei_boost": score_breakdown.get('dei_boost', 0),
            "final_score": score_breakdown.get('final_score', 0)
        },

        "explanation": {
            "top_reasons": top_reasons,
            "main_risks": main_risks,
            "candidate_actions": []  # Vuoto per company view
        },

        "feature_details": {
            "values": feature_values,
            "contributions": feature_contributions
        },

        "evidence": evidence,

        "flags": candidate_data.get('flags', {}),
        "dei_tags": candidate_data.get('dei_tags', {})
    }

    return xai_output


def build_xai_batch(
    candidates: List[Dict[str, Any]],
    jd_info: Dict[str, Any],
    thresholds: XAIThresholds = DEFAULT_THRESHOLDS
) -> Dict[str, Any]:
    """
    Costruisce l'output XAI per un batch di candidati (top N per una JD).

    Utile per generare spiegazioni per tutti i top 20 candidati di una JD
    in una sola chiamata.

    Args:
        candidates: Lista di candidati dal reranker (ognuno con la struttura
                    attesa da build_xai_company)
        jd_info: Info sulla JD {jd_id, title}
        thresholds: Soglie per la generazione

    Returns:
        Dict con:
        {
            "metadata": {...},
            "jd_info": {...},
            "candidates_xai": [...]  # Lista di XAI per ogni candidato
        }

    Example:
        >>> candidates = reranker_output['results'][0]['candidates'][:20]
        >>> jd_info = {"jd_id": "...", "title": "Frontend Developer"}
        >>> batch_xai = build_xai_batch(candidates, jd_info)
    """
    candidates_xai = []

    for candidate in candidates:
        # Estrai details se presenti
        details = candidate.get('details', {})

        # Genera XAI per questo candidato
        xai = build_xai_company(candidate, details, jd_info, thresholds)
        candidates_xai.append(xai)

    return {
        "metadata": {
            "generated_at": datetime.now().isoformat(),
            "xai_version": "1.0",
            "view_type": "company_batch",
            "total_candidates": len(candidates_xai),
            "jd_id": jd_info.get('jd_id', ''),
            "thresholds": {
                "cosine_strong": thresholds.COSINE_STRONG,
                "cosine_moderate": thresholds.COSINE_MODERATE,
                "skill_core_strong": thresholds.SKILL_CORE_STRONG,
                "skill_core_partial": thresholds.SKILL_CORE_PARTIAL,
                "missing_skills_high": thresholds.MISSING_SKILLS_HIGH,
                "experience_gap_high": thresholds.EXPERIENCE_GAP_HIGH
            }
        },
        "jd_info": jd_info,
        "candidates_xai": candidates_xai
    }


def enrich_reranker_output(
    reranker_output: Dict[str, Any],
    thresholds: XAIThresholds = DEFAULT_THRESHOLDS
) -> Dict[str, Any]:
    """
    Arricchisce l'output completo del reranker con le spiegazioni XAI.

    Prende l'intero output JSON del reranker (con tutti i risultati per tutte le JD)
    e aggiunge il campo 'xai' a ogni candidato.

    Args:
        reranker_output: Output completo del reranker con struttura:
            {
                "metadata": {...},
                "results": [
                    {
                        "jd_id": "...",
                        "total_candidates": N,
                        "candidates": [...]
                    },
                    ...
                ]
            }
        thresholds: Soglie per la generazione

    Returns:
        Lo stesso output con campo 'xai' aggiunto a ogni candidato

    Example:
        >>> import json
        >>> with open('rerank_output.json') as f:
        ...     reranker_output = json.load(f)
        >>> enriched = enrich_reranker_output(reranker_output)
        >>> with open('rerank_output_with_xai.json', 'w') as f:
        ...     json.dump(enriched, f, indent=2)
    """
    enriched = reranker_output.copy()
    enriched['metadata']['xai_version'] = "1.0"
    enriched['metadata']['xai_generated_at'] = datetime.now().isoformat()

    for jd_result in enriched.get('results', []):
        jd_info = {
            'jd_id': jd_result.get('jd_id', ''),
            'title': jd_result.get('title', '')  # Potrebbe non esserci
        }

        for candidate in jd_result.get('candidates', []):
            details = candidate.get('details', {})
            xai = build_xai_company(candidate, details, jd_info, thresholds)

            # Aggiungi solo la parte explanation (evita duplicazioni)
            candidate['xai'] = {
                "top_reasons": xai['explanation']['top_reasons'],
                "main_risks": xai['explanation']['main_risks'],
                "evidence": xai['evidence'],
                "quality_label": xai['match_summary']['quality_label']
            }

    return enriched


# ============================================================================
# UTILITY: Verifica coerenza score
# ============================================================================

def verify_score_consistency(
    feature_contributions: Dict[str, float],
    score_breakdown: Dict[str, float],
    tolerance: float = 0.01
) -> Dict[str, Any]:
    """
    Verifica che la somma dei contributi ricostruisca lo score.

    Requisito XAI: la somma dei contributi deve corrispondere allo score
    entro una tolleranza numerica.

    Args:
        feature_contributions: Dict dei contributi (w_i * x_i)
        score_breakdown: {linear_score_raw, dei_boost, ...}
        tolerance: Tolleranza per il confronto (default 0.01)

    Returns:
        {
            "is_consistent": bool,
            "sum_contributions": float,
            "linear_score_raw": float,
            "difference": float
        }
    """
    sum_contributions = sum(feature_contributions.values())
    linear_score_raw = score_breakdown.get('linear_score_raw', 0)
    difference = abs(sum_contributions - linear_score_raw)

    return {
        "is_consistent": difference <= tolerance,
        "sum_contributions": round(sum_contributions, 4),
        "linear_score_raw": round(linear_score_raw, 4),
        "difference": round(difference, 4)
    }


# ============================================================================
# PIPELINE PRINCIPALE
# ============================================================================

def load_reranker_output(config: XAIConfig = DEFAULT_CONFIG) -> Dict[str, Any]:
    """
    Carica l'output del reranker da file JSON.

    Args:
        config: Configurazione con il path del file

    Returns:
        Dict con l'output del reranker

    Raises:
        FileNotFoundError: Se il file non esiste
    """
    input_path = Path(config.RERANKER_OUTPUT_PATH)

    if not input_path.exists():
        raise FileNotFoundError(f"File reranker non trovato: {input_path}")

    with open(input_path, 'r', encoding='utf-8') as f:
        data = json.load(f)

    print(f"Loaded: {input_path}")
    print(f"  - JDs: {data.get('metadata', {}).get('total_jds', 'N/A')}")
    print(f"  - Candidates: {data.get('metadata', {}).get('total_candidates', 'N/A')}")

    return data


def generate_output_filename() -> str:
    """
    Genera il nome del file di output con timestamp.

    Returns:
        Nome file nel formato: xai_YYYY-MM-DD_HH-MM-SS.json
    """
    timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    return f"xai_{timestamp}.json"


def process_reranker_output(
    reranker_output: Dict[str, Any],
    thresholds: XAIThresholds = DEFAULT_THRESHOLDS
) -> Dict[str, Any]:
    """
    Processa l'output del reranker e genera le spiegazioni XAI.

    Args:
        reranker_output: Output completo del reranker
        thresholds: Soglie per la generazione delle spiegazioni

    Returns:
        Dict con struttura:
        {
            "metadata": {...},
            "results": [
                {
                    "jd_id": "...",
                    "jd_title": "...",
                    "total_candidates": N,
                    "candidates": [
                        {
                            ...dati originali...,
                            "xai": {...spiegazioni...}
                        }
                    ]
                }
            ]
        }
    """
    # Estrai metadata originali
    original_metadata = reranker_output.get('metadata', {})

    # Conta totali
    total_jds = len(reranker_output.get('results', []))
    total_candidates = sum(
        len(jd_result.get('candidates', []))
        for jd_result in reranker_output.get('results', [])
    )

    # Costruisci nuovi metadata
    metadata = {
        "generated_at": datetime.now().isoformat(),
        "xai_version": "1.0",
        "total_jds": total_jds,
        "total_candidates": total_candidates,
        "source_file": original_metadata.get('generated_at', 'unknown'),
        "scoring_method": original_metadata.get('scoring_method', 'linear_weighted_model'),
        "model_weights": original_metadata.get('weights', {}),
        "thresholds": {
            "cosine_strong": thresholds.COSINE_STRONG,
            "cosine_moderate": thresholds.COSINE_MODERATE,
            "skill_core_strong": thresholds.SKILL_CORE_STRONG,
            "skill_core_partial": thresholds.SKILL_CORE_PARTIAL,
            "skill_nice_threshold": thresholds.SKILL_NICE_THRESHOLD,
            "missing_skills_high": thresholds.MISSING_SKILLS_HIGH,
            "experience_gap_high": thresholds.EXPERIENCE_GAP_HIGH
        }
    }

    # Processa ogni JD
    results = []

    for jd_result in reranker_output.get('results', []):
        jd_id = jd_result.get('jd_id', '')
        jd_title = jd_result.get('title', '')  # Potrebbe non esserci

        jd_info = {
            'jd_id': jd_id,
            'title': jd_title
        }

        # Processa ogni candidato
        candidates_with_xai = []

        for candidate in jd_result.get('candidates', []):
            # Estrai details se presenti
            details = candidate.get('details', {})

            # Genera XAI
            xai = build_xai_company(candidate, details, jd_info, thresholds)

            # Crea nuovo candidato con XAI integrato
            candidate_with_xai = candidate.copy()
            candidate_with_xai['xai'] = {
                "quality_label": xai['match_summary']['quality_label'],
                "top_reasons": xai['explanation']['top_reasons'],
                "main_risks": xai['explanation']['main_risks'],
                "evidence": xai['evidence']
            }

            candidates_with_xai.append(candidate_with_xai)

        results.append({
            "jd_id": jd_id,
            "jd_title": jd_title,
            "total_candidates": len(candidates_with_xai),
            "candidates": candidates_with_xai
        })

    return {
        "metadata": metadata,
        "results": results
    }


def save_xai_output(
    xai_output: Dict[str, Any],
    config: XAIConfig = DEFAULT_CONFIG
) -> Path:
    """
    Salva l'output XAI su file JSON.

    Args:
        xai_output: Output XAI da salvare
        config: Configurazione con la directory di output

    Returns:
        Path del file salvato
    """
    # Crea directory se non esiste
    output_dir = Path(config.OUTPUT_DIR)
    output_dir.mkdir(parents=True, exist_ok=True)

    # Genera nome file
    filename = generate_output_filename()
    output_path = output_dir / filename

    # Salva
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(xai_output, f, indent=2, ensure_ascii=False)

    print(f"\nOutput saved: {output_path}")

    return output_path


def run_xai_pipeline(
    config: XAIConfig = DEFAULT_CONFIG,
    thresholds: XAIThresholds = DEFAULT_THRESHOLDS
) -> Path:
    """
    Esegue la pipeline XAI completa:
    1. Carica output reranker
    2. Genera spiegazioni per tutti i candidati
    3. Salva output in xai_output/

    Args:
        config: Configurazione paths
        thresholds: Soglie per le spiegazioni

    Returns:
        Path del file di output salvato

    Example:
        >>> from xai_builder import run_xai_pipeline
        >>> output_path = run_xai_pipeline()
        >>> print(f"XAI saved to: {output_path}")
    """
    print("=" * 60)
    print("XAI BUILDER - Processing Reranker Output")
    print("=" * 60)

    # 1. Carica input
    print("\n[1/3] Loading reranker output...")
    reranker_output = load_reranker_output(config)

    # 2. Processa
    print("\n[2/3] Generating XAI explanations...")
    xai_output = process_reranker_output(reranker_output, thresholds)

    # Stats
    total_reasons = sum(
        len(c.get('xai', {}).get('top_reasons', []))
        for r in xai_output['results']
        for c in r['candidates']
    )
    total_risks = sum(
        len(c.get('xai', {}).get('main_risks', []))
        for r in xai_output['results']
        for c in r['candidates']
    )

    print(f"  - Generated {total_reasons} reasons")
    print(f"  - Generated {total_risks} risks")

    # 3. Salva
    print("\n[3/3] Saving output...")
    output_path = save_xai_output(xai_output, config)

    print("\n" + "=" * 60)
    print("XAI PIPELINE COMPLETED")
    print("=" * 60)

    return output_path


# ============================================================================
# MAIN
# ============================================================================

if __name__ == "__main__":
    # Esegui pipeline completa
    try:
        output_path = run_xai_pipeline()
        print(f"\nSuccess! Output: {output_path}")
    except FileNotFoundError as e:
        print(f"\nError: {e}")
        print("Make sure to run the reranker first to generate rerank_results/rerank_output.json")
    except Exception as e:
        print(f"\nUnexpected error: {e}")
        raise

